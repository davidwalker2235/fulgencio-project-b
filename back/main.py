import asyncio
import base64
import datetime
import json
import os
import re
import sys
import unicodedata
import urllib.error
import urllib.request
from typing import Any, Optional

import requests
import websockets
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from firebase_admin import credentials, db, initialize_app
from fastapi.middleware.cors import CORSMiddleware
from openai import AzureOpenAI
from pydantic import BaseModel

load_dotenv()

app = FastAPI(title="GPT Realtime Voice API")

cors_origins = os.getenv(
    "CORS_ORIGINS",
    "http://localhost:3000,http://localhost:8080,http://127.0.0.1:3000,http://127.0.0.1:8080"
).split(",")

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT", "")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY", "")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION", "2024-10-01-preview")
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-realtime")
FIREBASE_DATABASE_URL = os.getenv("FIREBASE_DATABASE_URL", "")
FIREBASE_SERVICE_ACCOUNT_PATH = os.getenv("FIREBASE_SERVICE_ACCOUNT_PATH", "")
USER_DATA_API_URL = os.getenv("USER_DATA_API_URL", "").strip()
USER_DATA_API_TIMEOUT_SECONDS = int(os.getenv("USER_DATA_API_TIMEOUT_SECONDS", "5"))
USER_DATA_API_RETRIES = int(os.getenv("USER_DATA_API_RETRIES", "2"))

# URLs para eventos de robot (regalo y caricatura)
GIFT_ROBOT_API_URL = os.getenv("GIFT_ROBOT_API_URL", "aqui ir√° la URL del regalo")
CARICATURE_ROBOT_API_URL = os.getenv("CARICATURE_ROBOT_API_URL", "aqui ir√° la URL de la caricatura")
MODEL_IMAGE_NAME = os.getenv("MODEL_IMAGE_NAME", "gpt-image-1.5")
AZURE_OPENAI_IMAGE_API_VERSION = os.getenv(
    "AZURE_OPENAI_IMAGE_API_VERSION",
    os.getenv("AZURE_OPENAI_IMAGE_API_KEY", "2024-02-01"),
)
AZURE_OPENAI_IMAGE_PROMPT = os.getenv(
    "AZURE_OPENAI_IMAGE_PROMPT",
    "Make an exaggerated caricature of the person appearing in this photo in a line drawing style.",
)
AZURE_OPENAI_IMAGE_ENDPOINT = os.getenv(
    "AZURE_OPENAI_IMAGE_ENDPOINT",
    (
        f"{AZURE_OPENAI_ENDPOINT.rstrip('/')}/openai/deployments/{MODEL_IMAGE_NAME}/images/generations"
        if AZURE_OPENAI_ENDPOINT
        else ""
    ),
)
AZURE_OPENAI_IMAGE_EDITS_ENDPOINT = os.getenv(
    "AZURE_OPENAI_IMAGE_EDITS_ENDPOINT",
    (
        f"{AZURE_OPENAI_ENDPOINT.rstrip('/')}/openai/deployments/{MODEL_IMAGE_NAME}/images/edits"
        if AZURE_OPENAI_ENDPOINT
        else ""
    ),
)

client: Optional[AzureOpenAI] = None
firebase_app: Optional[Any] = None
active_sessions: dict[str, Any] = {}
current_status: str = "idle"
status_listener_started: bool = False

if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY:
    client = AzureOpenAI(
        api_key=AZURE_OPENAI_API_KEY,
        api_version=AZURE_OPENAI_API_VERSION,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
    )


def initialize_firebase():
    """
    Inicializa Firebase Admin SDK (Python) para Realtime Database.
    Documentaci√≥n base:
    https://firebase.google.com/docs/database/admin/save-data?hl=es-419&authuser=3#python
    """
    global firebase_app

    if not FIREBASE_DATABASE_URL:
        print("‚ö†Ô∏è FIREBASE_DATABASE_URL no configurado.")
        return

    if not FIREBASE_SERVICE_ACCOUNT_PATH:
        print("‚ÑπÔ∏è FIREBASE_SERVICE_ACCOUNT_PATH no configurado. Se usar√° fallback REST para lectura p√∫blica.")
        return

    try:
        cred = credentials.Certificate(FIREBASE_SERVICE_ACCOUNT_PATH)
        firebase_app = initialize_app(cred, {"databaseURL": FIREBASE_DATABASE_URL})
        print("‚úÖ Firebase Admin inicializado correctamente.")
    except Exception as err:
        firebase_app = None
        print(f"‚ö†Ô∏è Error inicializando Firebase Admin: {err}")
        print("‚ÑπÔ∏è Se usar√° fallback REST para lectura p√∫blica.")


def get_user_from_realtime_db(order_number: str) -> Optional[dict[str, Any]]:
    """
    Lee users/{order_number} desde Realtime Database.
    Prioriza Admin SDK; si no hay credenciales, usa REST p√∫blica.
    """
    if not FIREBASE_DATABASE_URL:
        return None

    if firebase_app is not None:
        try:
            users_ref = db.reference("users", app=firebase_app)
            value = users_ref.child(order_number).get()
            return value if isinstance(value, dict) else None
        except Exception as err:
            print(f"‚ö†Ô∏è Error leyendo Firebase Admin para {order_number}: {err}")

    # Fallback REST (√∫til si las reglas permiten lectura p√∫blica)
    url = f"{FIREBASE_DATABASE_URL.rstrip('/')}/users/{order_number}.json"
    try:
        with urllib.request.urlopen(url, timeout=5) as response:
            payload = response.read().decode("utf-8")
            value = json.loads(payload) if payload else None
            return value if isinstance(value, dict) else None
    except urllib.error.HTTPError as http_err:
        if http_err.code != 404:
            print(f"‚ö†Ô∏è Error HTTP en Firebase REST para {order_number}: {http_err}")
    except Exception as err:
        print(f"‚ö†Ô∏è Error en Firebase REST para {order_number}: {err}")

    return None


def update_user_fields_in_realtime_db(order_number: str, fields: dict[str, Any]) -> bool:
    """
    Actualiza campos parciales en users/{order_number}.
    Prioriza Admin SDK; si no hay credenciales, usa REST PATCH.
    """
    if not FIREBASE_DATABASE_URL:
        print("‚ùå FIREBASE_DATABASE_URL no configurado para actualizar Firebase.")
        return False

    if firebase_app is not None:
        try:
            users_ref = db.reference("users", app=firebase_app)
            users_ref.child(order_number).update(fields)
            return True
        except Exception as err:
            print(f"‚ö†Ô∏è Error actualizando Firebase Admin para {order_number}: {err}")

    try:
        url = f"{FIREBASE_DATABASE_URL.rstrip('/')}/users/{order_number}.json"
        payload = json.dumps(fields).encode("utf-8")
        request = urllib.request.Request(
            url,
            data=payload,
            headers={"Content-Type": "application/json"},
            method="PATCH",
        )
        with urllib.request.urlopen(request, timeout=10) as response:
            status = getattr(response, "status", 200)
            return 200 <= status < 300
    except Exception as err:
        print(f"‚ùå Error actualizando Firebase REST para {order_number}: {err}")
        return False


def extract_base64_payload(image_data: str) -> str:
    """
    Admite data URL o base64 directo y devuelve solo el payload base64.
    """
    if not image_data:
        return ""
    marker = "base64,"
    if marker in image_data:
        return image_data.split(marker, 1)[1].strip()
    return image_data.strip()


def parse_generated_base64_list(response_data: dict[str, Any]) -> list[str]:
    """
    Extrae una lista de base64 desde posibles formatos de respuesta del endpoint images.
    """
    results: list[str] = []

    data = response_data.get("data")
    if isinstance(data, list) and data:
        for item in data:
            if not isinstance(item, dict):
                continue
            b64_json = item.get("b64_json")
            if isinstance(b64_json, str) and b64_json.strip():
                results.append(b64_json.strip())

    output = response_data.get("output")
    if isinstance(output, list) and output:
        for item in output:
            if not isinstance(item, dict):
                continue
            b64_json = item.get("b64_json")
            if isinstance(b64_json, str) and b64_json.strip():
                results.append(b64_json.strip())
            content = item.get("content")
            if isinstance(content, list):
                for piece in content:
                    if isinstance(piece, dict):
                        b64_piece = piece.get("b64_json")
                        if isinstance(b64_piece, str) and b64_piece.strip():
                            results.append(b64_piece.strip())

    # Eliminar posibles duplicados preservando orden.
    deduped: list[str] = []
    seen: set[str] = set()
    for entry in results:
        if entry in seen:
            continue
        seen.add(entry)
        deduped.append(entry)

    return deduped


def call_image_generation_sync(photo_base64_or_data_url: str) -> list[str]:
    """
    Edita imagen usando gpt-image-1.5 en endpoint /images/edits
    enviando multipart/form-data (image + prompt), seg√∫n gu√≠a indicada.
    """
    if not AZURE_OPENAI_IMAGE_EDITS_ENDPOINT:
        raise RuntimeError("AZURE_OPENAI_IMAGE_EDITS_ENDPOINT no configurado")
    if not AZURE_OPENAI_API_KEY:
        raise RuntimeError("AZURE_OPENAI_API_KEY no configurado")

    raw_base64 = extract_base64_payload(photo_base64_or_data_url)
    if not raw_base64:
        raise RuntimeError("Foto base64 vac√≠a")

    try:
        image_bytes = base64.b64decode(raw_base64, validate=True)
    except Exception as err:
        raise RuntimeError(f"Base64 de foto inv√°lido: {err}") from err

    # Nombre/extensi√≥n orientativo; el backend recibe jpeg desde canvas por defecto.
    files = {
        "image": ("image_to_edit.jpg", image_bytes, "image/jpeg"),
    }
    data = {
        "prompt": AZURE_OPENAI_IMAGE_PROMPT,
        "n": "1",
    }
    headers = {
        "Authorization": f"Bearer {AZURE_OPENAI_API_KEY}",
    }

    version = AZURE_OPENAI_IMAGE_API_VERSION
    request_url = f"{AZURE_OPENAI_IMAGE_EDITS_ENDPOINT}?api-version={version}"
    print(f"üñºÔ∏è Edit endpoint fijo: {request_url}")
    response = requests.post(
        request_url,
        headers=headers,
        files=files,
        data=data,
        timeout=90,
    )
    print(f"üñºÔ∏è Status Foundry edits: {response.status_code}")

    if response.status_code != 200:
        raise RuntimeError(
            f"HTTP {response.status_code} {response.reason} "
            f"(api-version={version}). Body: {response.text}"
        )

    response_data = response.json()
    generated_base64_list = parse_generated_base64_list(response_data)
    if generated_base64_list:
        print(
            f"‚úÖ Caricaturas generadas correctamente (api-version={version}). "
            f"Cantidad: {len(generated_base64_list)}"
        )
        return generated_base64_list

    raise RuntimeError(
        f"200 sin b64_json (api-version={version}). Body: {response.text}"
    )


def normalize_text(text: str) -> str:
    """Normaliza texto para detectar n√∫meros con m√°s robustez."""
    lowered = text.lower().strip()
    normalized = unicodedata.normalize("NFKD", lowered)
    return "".join(ch for ch in normalized if not unicodedata.combining(ch))


def extract_order_number(text: str) -> Optional[str]:
    """
    Extrae n√∫mero de orden desde frases como:
    - "soy el n√∫mero 42"
    - "soy el n√∫mero 4, 2"
    - "mi codigo es cuatro dos"
    """
    if not text:
        return None

    normalized = normalize_text(text)

    # Buscar contexto m√≠nimo para evitar falsos positivos.
    intent_keywords = ("numero", "codigo", "orden", "id", "identificador", "soy")
    if not any(keyword in normalized for keyword in intent_keywords):
        return None

    # 1) N√∫mero continuo.
    contiguous_matches = re.findall(r"\b\d{1,6}\b", normalized)
    if contiguous_matches:
        return contiguous_matches[0]

    # 2) D√≠gitos separados por espacios, comas o guiones.
    separated_matches = re.findall(r"(?:\d[\s,.\-]*){2,6}", normalized)
    for raw in separated_matches:
        digits_only = "".join(ch for ch in raw if ch.isdigit())
        if 1 <= len(digits_only) <= 6:
            return digits_only

    # 3) N√∫mero expresado en palabras.
    word_to_digit = {
        "cero": "0",
        "uno": "1",
        "una": "1",
        "dos": "2",
        "tres": "3",
        "cuatro": "4",
        "cinco": "5",
        "seis": "6",
        "siete": "7",
        "ocho": "8",
        "nueve": "9",
    }
    word_pattern = r"\b(?:cero|uno|una|dos|tres|cuatro|cinco|seis|siete|ocho|nueve)\b"
    sequence_pattern = rf"(?:{word_pattern})(?:[\s,.\-]+(?:{word_pattern}))*"
    for seq in re.findall(sequence_pattern, normalized):
        words = re.findall(word_pattern, seq)
        if not words:
            continue
        digits = "".join(word_to_digit[w] for w in words if w in word_to_digit)
        if 1 <= len(digits) <= 6:
            return digits

    return None


# =============================================================================
# SISTEMA DE PROMPTS PARA FULGENCIO
# =============================================================================

REGLAS_CONVERSACION = """
=== REGLAS DE CONVERSACI√ìN (APLICAR SIEMPRE) ===

IDENTIDAD:
Eres Fulgencio, un asistente de voz amigable. Hablas con acento espa√±ol de Espa√±a.
Si te preguntan qui√©n eres: "Soy Fulgencio, creado por David Carmona, Enric Domingo 
y Jordi Rebull, todos expertos desarrolladores de ERNI Consulting."

TEMAS PERMITIDOS EN LA CONVERSACI√ìN:
1. EMPRESA: Pregunta d√≥nde trabaja el usuario y comenta algo breve sobre esa empresa.
2. PUESTO: Pregunta su puesto de trabajo y al√°balo brevemente.
3. TALENT ARENA: Pregunta qu√© espera del evento y qu√© le est√° gustando m√°s.
4. ERNI CONSULTING: Pregunta si conoce ERNI. Si s√≠, al√°balo y menciona que puede 
   hablar con el personal del stand. Si no, explica que ERNI es una consultora 
   tecnol√≥gica suiza especializada en software, cloud, IA y transformaci√≥n digital.
5. TU NOMBRE: Solo si preguntan, di que eres Fulgencio (ver IDENTIDAD).

RESTRICCIONES:
- Si el usuario pregunta algo fuera de estos temas, redirige elegantemente 
  la conversaci√≥n hacia uno de los temas permitidos.
- Ejemplo: "Eso es interesante, pero cu√©ntame, ¬øen qu√© empresa trabajas?"
- Navega entre los temas de forma natural buscando conexiones.
- S√© amable, profesional y con un toque de humor.
- Respuestas breves: m√°ximo 2-3 frases.
"""


def build_welcome_prompt() -> str:
    """Prompt de bienvenida cuando inicia la conversaci√≥n."""
    return (
        REGLAS_CONVERSACION + "\n"
        "=== SITUACI√ìN ACTUAL ===\n\n"
        "Acabas de conectarte con un nuevo usuario.\n\n"
        "TU TAREA:\n"
        "1. Pres√©ntate: 'Hola, soy Fulgencio'\n"
        "2. Ofrece las dos opciones:\n"
        "   - 'Puedo darte un regalo'\n"
        "   - 'O si me dices tu n√∫mero de orden, puedo hacerte una caricatura "
        "     divertida basada en la foto que nos has dado'\n"
        "3. Pregunta: '¬øQu√© te apetece?'\n\n"
        "DETECCI√ìN DE INTENCI√ìN:\n"
        "- Si dice 'regalo', 'quiero regalo', 'dame el regalo', etc. -> Quiere REGALO\n"
        "- Si dice un n√∫mero, 'caricatura', 'mi n√∫mero es...', 'quiero la caricatura', "
        "  'soy el X', etc. -> Quiere CARICATURA\n"
    )


def build_conversation_prompt(user_name: str = None) -> str:
    """Prompt para la conversaci√≥n despu√©s de elegir regalo o caricatura."""
    name_part = f"El usuario se llama {user_name}. Dir√≠gete a √©l por su nombre.\n\n" if user_name else ""
    return (
        REGLAS_CONVERSACION + "\n"
        "=== SITUACI√ìN ACTUAL ===\n\n"
        + name_part +
        "El usuario ya ha elegido su opci√≥n (regalo o caricatura) y el proceso est√° en marcha.\n"
        "Tu tarea ahora es mantener una conversaci√≥n amena mientras espera.\n\n"
        "NAVEGACI√ìN:\n"
        "- Empieza preguntando por su empresa o su puesto\n"
        "- Navega naturalmente entre los 5 temas permitidos\n"
        "- Busca conexiones entre las respuestas para fluir en la conversaci√≥n\n"
    )


def send_user_data_to_external_api_sync(order_number: str, user_data: dict[str, Any]) -> bool:
    """
    Env√≠a datos del usuario a una API externa (si est√° configurada).
    Reintenta en errores temporales.
    """
    if not USER_DATA_API_URL:
        return False

    payload = {
        "orderNumber": order_number,
        "user": user_data,
    }
    body = json.dumps(payload).encode("utf-8")

    last_error: Optional[Exception] = None
    attempts = max(1, USER_DATA_API_RETRIES + 1)

    for _ in range(attempts):
        try:
            request = urllib.request.Request(
                USER_DATA_API_URL,
                data=body,
                headers={"Content-Type": "application/json"},
                method="POST",
            )
            with urllib.request.urlopen(request, timeout=USER_DATA_API_TIMEOUT_SECONDS) as response:
                status = getattr(response, "status", 200)
                if 200 <= status < 300:
                    return True
                last_error = RuntimeError(f"status={status}")
        except Exception as err:
            last_error = err

    if last_error is not None:
        print(f"‚ö†Ô∏è No se pudo enviar datos a API externa: {last_error}")
    return False


async def trigger_gift_robot(order_number: str) -> bool:
    """
    Dispara evento para mover el robot de regalo.
    Env√≠a el n√∫mero de orden al robot.
    """
    print(f"üéÅ Disparando evento de regalo para usuario {order_number}...")
    try:
        response = await asyncio.to_thread(
            lambda: requests.post(
                GIFT_ROBOT_API_URL,
                json={"orderNumber": order_number, "action": "gift"},
                timeout=10,
            )
        )
        if 200 <= response.status_code < 300:
            print(f"‚úÖ Robot regalo activado para usuario {order_number}")
            return True
        else:
            print(f"‚ö†Ô∏è Robot regalo respondi√≥ con status {response.status_code}")
            return False
    except Exception as e:
        print(f"se ha lanzado evento para regalo (error: {e})")
        return False


async def trigger_caricature_robot(order_number: str, caricature_base64: str) -> bool:
    """
    Dispara evento para que el robot dibuje la caricatura.
    Env√≠a la imagen en base64 al robot.
    """
    print(f"üñºÔ∏è Disparando evento de caricatura para usuario {order_number}...")
    try:
        response = await asyncio.to_thread(
            lambda: requests.post(
                CARICATURE_ROBOT_API_URL,
                json={
                    "orderNumber": order_number,
                    "action": "caricature",
                    "image": caricature_base64,
                },
                timeout=30,
            )
        )
        if 200 <= response.status_code < 300:
            print(f"‚úÖ Robot caricatura activado para usuario {order_number}")
            return True
        else:
            print(f"‚ö†Ô∏è Robot caricatura respondi√≥ con status {response.status_code}")
            return False
    except Exception as e:
        print(f"se ha lanzado evento para caricatura (error: {e})")
        return False


def setup_firebase_status_listener():
    """
    Configura listener para cambios en el nodo 'status' de Firebase.
    Cuando cambia a 'painting', notifica a las sesiones activas.
    """
    global status_listener_started, current_status
    
    if status_listener_started:
        return
    
    if firebase_app is None:
        print("‚ö†Ô∏è Firebase no inicializado, no se puede configurar listener de status")
        return
    
    def on_status_change(event):
        global current_status
        new_status = event.data
        if new_status == current_status:
            return
        
        old_status = current_status
        current_status = new_status if new_status else "idle"
        print(f"üì° Status Firebase cambi√≥: {old_status} -> {current_status}")
        
        if current_status == "painting":
            print("üé® Estado 'painting' detectado - se aplicar√°n instrucciones de conversaci√≥n")
    
    try:
        ref = db.reference("status")
        ref.listen(on_status_change)
        status_listener_started = True
        print("‚úÖ Listener de status de Firebase configurado correctamente")
    except Exception as e:
        print(f"‚ö†Ô∏è Error configurando listener de status: {e}")


initialize_firebase()
setup_firebase_status_listener()


class CaricatureGenerationRequest(BaseModel):
    orderNumber: str
    photoBase64: str


@app.get("/")
async def root():
    """Endpoint de salud"""
    return {
        "status": "ok",
        "message": "GPT Realtime Voice API est√° funcionando",
        "model": MODEL_NAME,
        "configured": client is not None,
    }


@app.get("/health")
async def health():
    """Endpoint de salud detallado"""
    return {
        "status": "healthy",
        "endpoint_configured": bool(AZURE_OPENAI_ENDPOINT),
        "api_key_configured": bool(AZURE_OPENAI_API_KEY),
    }


@app.get("/firebase/health")
async def firebase_health():
    """Estado de integraci√≥n Firebase en backend."""
    return {
        "database_url_configured": bool(FIREBASE_DATABASE_URL),
        "service_account_path_configured": bool(FIREBASE_SERVICE_ACCOUNT_PATH),
        "admin_sdk_initialized": firebase_app is not None,
    }


@app.get("/firebase/users/{order_number}")
async def firebase_get_user(order_number: str):
    """Lee users/{order_number} en Realtime Database."""
    user = get_user_from_realtime_db(order_number)
    return {
        "order_number": order_number,
        "found": user is not None,
        "user": user,
    }


@app.post("/photo/generate-caricature")
async def generate_caricature(payload: CaricatureGenerationRequest):
    """
    Genera caricaturas desde foto usando gpt-image-1.5 y las guarda en
    users/{order}/caricatures (array).
    """
    order_number = payload.orderNumber.strip()
    print("========================================")
    print("üü¶ Inicio generaci√≥n de caricatura")
    print(f"üßæ orderNumber: {order_number}")
    print("========================================")

    if not order_number:
        raise HTTPException(status_code=400, detail="orderNumber es obligatorio")
    if not payload.photoBase64.strip():
        raise HTTPException(status_code=400, detail="photoBase64 es obligatorio")

    try:
        print("1) Generando caricatura en Azure Foundry...")
        caricatures_base64 = await asyncio.to_thread(
            call_image_generation_sync,
            payload.photoBase64,
        )
        print(f"2) Caricaturas generadas. Total: {len(caricatures_base64)}")
        for i, b64_img in enumerate(caricatures_base64, start=1):
            print(f"   - Caricatura #{i}: longitud base64={len(b64_img)}")

        caricatures_data_urls = [
            f"data:image/png;base64,{img_b64}" for img_b64 in caricatures_base64
        ]

        print("3) Guardando caricaturas en Firebase...")
        updated_ok = await asyncio.to_thread(
            update_user_fields_in_realtime_db,
            order_number,
            {
                "caricatures": caricatures_data_urls,
                "caricaturesTimestamp": datetime.datetime.utcnow().isoformat() + "Z",
            },
        )
        if not updated_ok:
            raise RuntimeError("No se pudo guardar caricatures en Firebase")

        print(f"‚úÖ Caricaturas guardadas en users/{order_number}/caricatures")
        return {
            "ok": True,
            "orderNumber": order_number,
            "storedInFirebase": True,
            "generatedCount": len(caricatures_data_urls),
        }
    except HTTPException:
        raise
    except Exception as err:
        print(f"‚ùå Error en generaci√≥n/guardado de caricatura: {err}")
        raise HTTPException(status_code=500, detail=str(err))


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    Endpoint WebSocket para manejar la conversaci√≥n de voz en tiempo real.
    Recibe audio del frontend y lo reenv√≠a al modelo GPT Realtime de Microsoft Foundry.
    """
    await websocket.accept()
    
    if not client:
        await websocket.send_json({
            "type": "error",
            "message": "Azure OpenAI no est√° configurado. Verifica las variables de entorno."
        })
        await websocket.close()
        return

    try:
        endpoint_base = AZURE_OPENAI_ENDPOINT.rstrip('/')
        if endpoint_base.startswith('https://'):
            endpoint_base = endpoint_base.replace('https://', 'wss://')
        elif endpoint_base.startswith('http://'):
            endpoint_base = endpoint_base.replace('http://', 'ws://')
        
        realtime_url = f"{endpoint_base}/openai/realtime?deployment={MODEL_NAME}&api-version={AZURE_OPENAI_API_VERSION}"
        
        print(f"Intentando conectar a: {realtime_url.replace(AZURE_OPENAI_API_KEY, '***')}")
        
        headers = {
            "api-key": AZURE_OPENAI_API_KEY,
        }

        try:
            async with websockets.connect(
                realtime_url,
                additional_headers=headers,
            ) as realtime_ws:
                await handle_realtime_connection(realtime_ws, websocket)
        except Exception as e:
            print(f"Error con 'deployment', intentando con 'model': {e}")
            # Si falla con deployment, intentar con model
            realtime_url = f"{endpoint_base}/openai/realtime?model={MODEL_NAME}&api-version={AZURE_OPENAI_API_VERSION}"
            print(f"Intentando conectar a: {realtime_url}")
            async with websockets.connect(
                realtime_url,
                additional_headers=headers,
            ) as realtime_ws:
                await handle_realtime_connection(realtime_ws, websocket)
    
    except Exception as e:
        print(f"Error general en WebSocket: {e}")
        try:
            if websocket.client_state.name != "DISCONNECTED":
                await websocket.send_json({
                    "type": "error",
                    "message": f"Error al conectar con GPT Realtime: {str(e)}"
                })
        except:
            pass
    finally:
        try:
            if websocket.client_state.name != "DISCONNECTED":
                await websocket.close()
        except:
            pass


async def handle_realtime_connection(realtime_ws, websocket):
    """Maneja la conexi√≥n con GPT Realtime una vez establecida"""
    session_ctx: dict[str, Any] = {
        "latest_user_text": "",
        "is_user_locked": False,
        "locked_order_number": None,
        "locked_user_data": None,
        "initial_response_sent": False,
    }

    session_init = {
        "type": "session.update",
        "session": {
            "modalities": ["text", "audio"],
            "instructions": build_welcome_prompt(),
            "voice": "alloy",
            "input_audio_format": "pcm16",
            "output_audio_format": "pcm16",
            "input_audio_transcription": {
                "model": "whisper-1"
            },
            "turn_detection": {
                "type": "server_vad",
                "threshold": 0.5,
                "prefix_padding_ms": 300,
                "silence_duration_ms": 500,
                "create_response": False,
            },
            "input_audio_transcription": {
                "model": "whisper-1"
            }
        }
    }
    await realtime_ws.send(json.dumps(session_init))

    async def resolve_user_context_if_needed() -> None:
        """
        Detecta n√∫mero de orden en el √∫ltimo texto del usuario y, si encuentra
        datos en Firebase, bloquea el contexto para esta sesi√≥n.
        """
        if session_ctx["is_user_locked"]:
            return

        latest_text = session_ctx.get("latest_user_text", "")
        order_number = extract_order_number(latest_text)
        if not order_number:
            return

        user_data = await asyncio.to_thread(get_user_from_realtime_db, order_number)
        '''
        print(f"user_data: {user_data}")
        '''
        if not user_data:
            print(f"‚ö†Ô∏è N√∫mero detectado pero sin datos en Firebase: {order_number}")
            return

        session_ctx["is_user_locked"] = True
        session_ctx["locked_order_number"] = order_number
        session_ctx["locked_user_data"] = user_data
        print(f"se ha detectado que se ha pedido el n√∫mero: {order_number}")
        resolved_name = (
            str(
                user_data.get("fullName")
                or user_data.get("name")
                or user_data.get("nombre")
                or ""
            ).strip()
        )
        print(f"Nombre resuelto desde Firebase: {resolved_name or '(vac√≠o)'}")
        resolved_caricatures = user_data.get("caricatures")
        resolved_photo = user_data.get("photo")
        if isinstance(resolved_caricatures, list):
            print(f"Caricaturas detectadas para usuario: {len(resolved_caricatures)}")
        else:
            print("Caricaturas detectadas para usuario: 0")
        if resolved_photo:
            print(f"Foto del usuario detectada: {len(str(resolved_photo))} caracteres")

        # Enviar al frontend el contexto resuelto (incluyendo caricaturas y foto) para UI.
        try:
            await websocket.send_json({
                "type": "user.context.resolved",
                "orderNumber": order_number,
                "fullName": resolved_name,
                "caricatures": (
                    resolved_caricatures
                    if isinstance(resolved_caricatures, list)
                    else []
                ),
                "photo": resolved_photo if isinstance(resolved_photo, str) else None,
            })
            print("‚úÖ Evento user.context.resolved enviado al frontend.")
        except Exception as err:
            print(f"‚ö†Ô∏è No se pudo enviar user.context.resolved al frontend: {err}")

        # Refuerzo fuerte: fijar contexto personalizado en la sesi√≥n realtime.
        user_name = resolved_name or None
        session_instructions = build_conversation_prompt(user_name)
        
        session_update = {
            "type": "session.update",
            "session": {
                "instructions": session_instructions
            },
        }
        try:
            await realtime_ws.send(json.dumps(session_update))
            print("‚úÖ session.update con prompt de conversaci√≥n enviado.")
        except Exception as err:
            print(f"‚ö†Ô∏è No se pudo enviar session.update: {err}")

        if USER_DATA_API_URL:
            await asyncio.to_thread(send_user_data_to_external_api_sync, order_number, user_data)

    def inject_personalization_in_response(message: dict[str, Any]) -> dict[str, Any]:
        """
        A√±ade instrucciones personalizadas justo antes de pedir respuesta al modelo.
        """
        user_data = session_ctx.get("locked_user_data") or {}
        user_name = None
        
        if session_ctx["is_user_locked"] and isinstance(user_data, dict):
            user_name = str(
                user_data.get("fullName")
                or user_data.get("name")
                or user_data.get("nombre")
                or ""
            ).strip() or None

        # Usar prompt de conversaci√≥n si ya tenemos usuario, si no el de bienvenida
        if session_ctx["is_user_locked"]:
            personalization = build_conversation_prompt(user_name)
        else:
            personalization = build_welcome_prompt()

        response_payload = message.get("response")
        if not isinstance(response_payload, dict):
            response_payload = {}

        existing_instructions = response_payload.get("instructions")
        if isinstance(existing_instructions, str) and existing_instructions.strip():
            response_payload["instructions"] = (
                f"{personalization}\n\n{existing_instructions.strip()}"
            )
        else:
            response_payload["instructions"] = personalization

        message["response"] = response_payload
        return message

    async def trigger_response_create() -> None:
        """Dispara una respuesta del modelo con el prompt ya personalizado."""
        response_msg = {"type": "response.create"}
        response_msg = inject_personalization_in_response(response_msg)
        await realtime_ws.send(json.dumps(response_msg))

    # Respuesta inicial de la sesi√≥n (sin esperar a frontend).
    await trigger_response_create()
    session_ctx["initial_response_sent"] = True

    async def forward_to_realtime():
        try:
            while True:
                try:
                    data = await websocket.receive()
                except RuntimeError as e:
                    if "disconnect" in str(e).lower():
                        print("Cliente desconectado (receive)")
                        break
                    raise
                
                if "bytes" in data:
                    audio_data = data["bytes"]
                    audio_size = len(audio_data)
                    if audio_size > 0:
                        audio_base64 = base64.b64encode(audio_data).decode("utf-8")
                        try:
                            audio_event = {
                                "type": "input_audio_buffer.append",
                                "audio": audio_base64
                            }
                            await realtime_ws.send(json.dumps(audio_event))
                            if audio_size % 100 == 0:
                                print(f"Audio recibido y enviado a GPT Realtime: {audio_size} bytes")
                        except websockets.exceptions.ConnectionClosed:
                            print("Conexi√≥n con GPT Realtime cerrada (enviando audio)")
                            break
                    else:
                        print("Advertencia: Audio recibido con 0 bytes")
                    
                elif "text" in data:
                    try:
                        message = json.loads(data["text"])
                        message_type = message.get("type", "unknown")
                        print(f"Recibido del frontend: {message_type}")

                        # Forzar control manual de respuestas en cualquier session.update de frontend.
                        if message_type == "session.update":
                            session_payload = message.get("session")
                            if isinstance(session_payload, dict):
                                td = session_payload.get("turn_detection")
                                if isinstance(td, dict):
                                    td["create_response"] = False

                        # Captura mensajes de texto de usuario si vienen por item.create.
                        should_trigger_manual_response = False
                        if message_type == "conversation.item.create":
                            item = message.get("item", {})
                            role = item.get("role")
                            content = item.get("content", [])
                            if role == "user" and isinstance(content, list):
                                text_chunks: list[str] = []
                                for chunk in content:
                                    if (
                                        isinstance(chunk, dict)
                                        and chunk.get("type") == "input_text"
                                        and isinstance(chunk.get("text"), str)
                                    ):
                                        text_chunks.append(chunk["text"])
                                if text_chunks:
                                    session_ctx["latest_user_text"] = " ".join(text_chunks).strip()
                                    should_trigger_manual_response = True

                        # Bloquear response.create del frontend: lo controla el backend
                        # para garantizar que Firebase se procese antes de responder.
                        if message_type == "response.create":
                            print("‚ÑπÔ∏è response.create recibido desde frontend, se ignora (modo control backend).")
                            continue

                        await realtime_ws.send(json.dumps(message))

                        # Flujo manual para mensajes de texto de usuario.
                        if should_trigger_manual_response:
                            await resolve_user_context_if_needed()
                            await trigger_response_create()
                    except json.JSONDecodeError:
                        pass
                    except websockets.exceptions.ConnectionClosed:
                        print("Conexi√≥n con GPT Realtime cerrada (enviando texto)")
                        break
                        
        except WebSocketDisconnect:
            print("Cliente desconectado")
        except Exception as e:
            print(f"Error en forward_to_realtime: {e}")
            try:
                if not websocket.client_state.name == "DISCONNECTED":
                    await websocket.send_json({
                        "type": "error",
                        "message": str(e)
                    })
            except:
                pass

    async def forward_to_client():
        try:
            while True:
                message = await realtime_ws.recv()
                if isinstance(message, str):
                    try:
                        data = json.loads(message)
                        """
                        print(f"Recibido de GPT Realtime: {data.get('type', 'unknown')}")
                        """

                        # Captura transcripci√≥n final de audio de usuario.
                        if data.get("type") == "conversation.item.input_audio_transcription.completed":
                            transcript = data.get("transcript")
                            if isinstance(transcript, str) and transcript.strip():
                                session_ctx["latest_user_text"] = transcript.strip()
                                await resolve_user_context_if_needed()
                                # Solo despu√©s de transcribir y resolver Firebase.
                                await trigger_response_create()

                        try:
                            if websocket.client_state.name != "DISCONNECTED":
                                await websocket.send_json(data)
                        except RuntimeError:
                            print("Cliente desconectado, no se puede enviar mensaje")
                            break
                    except json.JSONDecodeError:
                        try:
                            if websocket.client_state.name != "DISCONNECTED":
                                await websocket.send_text(message)
                        except RuntimeError:
                            break
                elif isinstance(message, bytes):
                    try:
                        if websocket.client_state.name != "DISCONNECTED":
                            await websocket.send_bytes(message)
                    except RuntimeError:
                        print("Cliente desconectado, no se puede enviar audio")
                        break
                    
        except websockets.exceptions.ConnectionClosed:
            print("Conexi√≥n con GPT Realtime cerrada")
            try:
                if websocket.client_state.name != "DISCONNECTED":
                    await websocket.send_json({
                        "type": "error",
                        "message": "Conexi√≥n con GPT Realtime cerrada"
                    })
            except:
                pass
        except Exception as e:
            print(f"Error en forward_to_client: {e}")
            try:
                if websocket.client_state.name != "DISCONNECTED":
                    await websocket.send_json({
                        "type": "error",
                        "message": str(e)
                    })
            except:
                pass

    try:
        initial_response = await realtime_ws.recv()
        if isinstance(initial_response, str):
            response_data = json.loads(initial_response)
            print(f"Respuesta inicial de GPT Realtime: {response_data.get('type', 'unknown')}")
            if websocket.client_state.name != "DISCONNECTED":
                await websocket.send_json(response_data)
    except Exception as e:
        print(f"Error esperando respuesta inicial: {e}")
    
    try:
        await asyncio.gather(
            forward_to_realtime(),
            forward_to_client(),
            return_exceptions=True
        )
    except Exception as e:
        print(f"Error en WebSocket: {e}")
        try:
            if websocket.client_state.name != "DISCONNECTED":
                await websocket.send_json({
                    "type": "error",
                    "message": str(e)
                })
        except:
            pass
        try:
            await websocket.close()
        except:
            pass
    finally:
        # Limpieza expl√≠cita de contexto al terminar la sesi√≥n.
        session_ctx["latest_user_text"] = ""
        session_ctx["is_user_locked"] = False
        session_ctx["locked_order_number"] = None
        session_ctx["locked_user_data"] = None


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

